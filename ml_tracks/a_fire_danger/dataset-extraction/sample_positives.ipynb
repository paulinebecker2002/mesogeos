{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shapely import wkt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD the path to the burned areas file\n",
    "gdf = gpd.read_file(\"/hkfs/work/workspace/scratch/uyxib-mesogeos2/auxilliary/burned_areas_shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD the path to the datacube\n",
    "ds = xr.open_zarr(\"/hkfs/work/workspace/scratch/uyxib-mesogeos2/mesogeos_cube.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD the path to the biomes\n",
    "biome = gpd.read_file(\"/hkfs/work/workspace/scratch/uyxib-mesogeos2/auxilliary/ecoregions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biome=biome[(biome['BIOME_NUM']== 12.0) & (biome['REALM']=='Palearctic')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change the CRS of gdf to EPSG:4326\n",
    "# slice gdf to rows with IGNITION_D >= '2002-04-01'\n",
    "gdf = gdf[gdf['IGNITION_D'] >= '2006-04-02'].reset_index(drop=True)\n",
    "gdf = gdf[gdf['IGNITION_D'] <= '2022-09-30'].reset_index(drop=True)\n",
    "gdf = gdf[gdf['AREA_HA'].astype(float) >= 30]\n",
    "# convert FIREDATE column to datetime\n",
    "gdf['IGNITION_D'] = pd.to_datetime(gdf['IGNITION_D'])\n",
    "# subtract 1 day from FIREDATE\n",
    "gdf['IGNITION_D'] = gdf['IGNITION_D'] - pd.Timedelta(days=1)\n",
    "# get the year of FIREDATE\n",
    "gdf['IGNITION_YEAR'] = gdf['IGNITION_D'].dt.year\n",
    "# converts the WKT string into a Shapely Polygon object\n",
    "gdf['geometry_h'] = gdf['geometry_h'].apply(wkt.loads)\n",
    "gdf = gdf.set_geometry('geometry_h') #treat geometry_h as the main geometry column,\n",
    "gdf.crs = \"EPSG:5643\"\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.sjoin(gdf, biome, how = 'inner', predicate = 'intersects').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the save directories\n",
    "save_dir = \"/hkfs/work/workspace/scratch/uyxib-mesogeos2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:53:29.354013Z",
     "start_time": "2025-05-08T08:53:28.968681Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m patch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m125\u001B[39m\n\u001B[1;32m      3\u001B[0m patch_half \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m125\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[0;32m----> 4\u001B[0m len_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mds\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m len_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ds[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      7\u001B[0m s_cl \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "lag = 30\n",
    "patch_size = 125\n",
    "patch_half = 125//2\n",
    "len_x = len(ds['x'])\n",
    "len_y = len(ds['y'])\n",
    "\n",
    "s_cl = 0\n",
    "s_seg = 0\n",
    "for i in tqdm(range(len(gdf))):\n",
    "    np_var = {}\n",
    "    date_format = '%Y-%m-%d'\n",
    "    ignition_date = gdf.loc[i, 'IGNITION_D']\n",
    "    ignition_xy = gdf.loc[i, 'geometry_h'] #ignition point at center \"centroid\" of geometry_h polygon -> not super accurate as Fires can start at the edge or corner of a burned area\n",
    "              \n",
    "    ign_date_str  = (ignition_date).strftime('%Y-%m-%d')\n",
    "    ign_date_lag_str = (ignition_date - pd.Timedelta(days=lag-1)).strftime('%Y-%m-%d')\n",
    "              \n",
    "    pos_sample_ds = ds.sel(time=slice(ign_date_lag_str, ign_date_str))\n",
    "    \n",
    "    pos_sample = pos_sample_ds.sel(x=ignition_xy.x, y=ignition_xy.y, method='nearest') #takes the nearest pixel close to the ignition point from geometry_h\n",
    "    x_idx = np.where(pos_sample_ds['x']==pos_sample['x'].values)[0].item()\n",
    "    y_idx = np.where(pos_sample_ds['y']==pos_sample['y'].values)[0].item()\n",
    "\n",
    "    #checks if ignition point is in the border of the datacube\n",
    "    if ((x_idx - patch_half < 0) or (x_idx + patch_half + 1 >= len_x) or (y_idx - patch_half < 0) or (y_idx + patch_half + 1 >= len_y)): \n",
    "        print('border')\n",
    "        continue\n",
    "    \n",
    "    #extracts all data points of the data patch in a 125x125 pixel square (62 pixel in each direction, x and y)   \n",
    "    pos_sample_ds = pos_sample_ds.isel(x=slice(x_idx - patch_half,x_idx + patch_half + 1),\n",
    "                                      y=slice(y_idx - patch_half,y_idx + patch_half + 1)) \n",
    "    \n",
    "    pos_sample_ds_vars = list(pos_sample_ds.keys())  #get the variables of all points of data patch\n",
    "    year = str(pos_sample_ds.time.dt.year.values[-1]) #remember the year of the last time step of the data patch to add static variables later\n",
    "    for var in pos_sample_ds_vars:\n",
    "        if var == 'population' or 'lc' in var:\n",
    "            del pos_sample_ds[var]\n",
    "            if year == '2006':\n",
    "                pos_sample_ds[var] = ds[var].sel(time=slice('2006-04-01', '2006-04-01'))[0].isel(x=slice(x_idx - patch_half,x_idx + patch_half + 1),\n",
    "                                      y=slice(y_idx - patch_half,y_idx + patch_half + 1)) \n",
    "            else:\n",
    "                dt = str(year) + '-01-01'\n",
    "                pos_sample_ds[var] = ds[var].sel(time=slice(dt, dt))[0].isel(x=slice(x_idx - patch_half,x_idx + patch_half + 1),\n",
    "                                      y=slice(y_idx - patch_half,y_idx + patch_half + 1))\n",
    "                \n",
    "    del pos_sample_ds['spatial_ref']\n",
    "    pos_sample_ds = pos_sample_ds.load()\n",
    "    \n",
    "\n",
    "    pos_sample_ds = pos_sample_ds.isel(x=patch_half, y=patch_half) #just takes central ignition point from 125x125 patch\n",
    "    pos_sample_ds = pos_sample_ds.load() #load in RAM otherwise xarray lazy\n",
    "    pos_sample_ds['burned_area_has'] = float(gdf.loc[i, 'AREA_HA']) #add burned area -> size of the fire in hektar \n",
    "    if pd.notnull(pos_sample_ds['t2m'][0]): #adds only if t2m of sample is not null\n",
    "        if s_cl == 0: #inizialize the dataframe\n",
    "            df = pos_sample_ds.to_dataframe() \n",
    "            df['time_idx'] = np.arange(0,lag)\n",
    "            df['sample'] = s_cl\n",
    "        else: #append to the dataframe\n",
    "            df1 = pos_sample_ds.to_dataframe()\n",
    "            df1['time_idx'] = np.arange(0,lag)\n",
    "            df1['sample'] = s_cl\n",
    "            df = pd.concat([df, df1], axis=0)\n",
    "            del df1 #delete the df1 to save memory\n",
    "        s_cl+=1\n",
    "    del pos_sample_ds\n",
    "    gc.collect()\n",
    "path_df = save_dir / 'positives.csv'\n",
    "df.to_csv(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e777a3fa5c7295abfc04ae8075218d3d543836079b2092325f3aac9db08acff8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
